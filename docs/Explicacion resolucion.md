explicacion_proceso: |
  # üß† Proceso de Dise√±o y Resoluci√≥n del ETL ‚Äì Cotizaciones AwesomeAPI

  Este documento tiene como objetivo explicar en detalle c√≥mo estructur√© y resolv√≠ el proyecto t√©cnico de ETL solicitado, utilizando la API p√∫blica de AwesomeAPI para consumir cotizaciones de monedas extranjeras.

  La soluci√≥n fue dise√±ada con foco en modularidad, trazabilidad y buenas pr√°cticas de ingenier√≠a de datos, simulando un entorno real de trabajo con arquitectura por capas y registros detallados de cada etapa.

  ---

  ## üéØ Objetivo general del challenge

  Se solicitaba:

  1. Consultar cotizaciones de los pares: USD/BRL, EUR/BRL y BTC/BRL (yo decid√≠ generalizarlo a todos los pares `*-BRL`)
  2. Estandarizar los campos resultantes en el siguiente formato:

     ```
     base_currency
     destination_currency
     purchase_value
     sale_value
     date_time (UTC y formato: YYYY-MM-DD HH:mm:ss)
     ```

  3. Guardar los datos normalizados en `.csv`
  4. (Diferencial agregado) Subir la informaci√≥n a una base de datos relacional o BigQuery

  ---


---

## üîé Explicaci√≥n t√©cnica por m√≥dulo

### üîπ 1. Extracci√≥n (`o1_extraction`)
**Clase:** `CurrencyExtractor`

- Consulta el endpoint `/available` para obtener todos los pares posibles
- Filtra √∫nicamente los que terminan en `-BRL` (din√°micamente)
- Por cada par, solicita los √∫ltimos 180 d√≠as de cotizaciones
- Guarda un `.json` por par en la carpeta `data/o1_bronze/`

‚úîÔ∏è Esta etapa act√∫a como "ingesta cruda" (bronze), manteniendo el dato sin tocar.

---

### üîπ 2. Limpieza y unificaci√≥n (`o2_transformation`)
**Clase:** `DFsCurrencies`

- Lee todos los JSON desde la capa `bronze`
- Extrae la metadata (`code`, `codein`, `name`, `create_date`) del primer registro
- Concatena todos los valores hist√≥ricos en un solo DataFrame
- Devuelve un √∫nico DF consolidado y limpio, listo para transformar

‚úîÔ∏è La separaci√≥n entre extracci√≥n y transformaci√≥n me permite revisar los datos sin procesarlos a√∫n.

---

### üîπ 3. Transformaci√≥n (`o3_transformation`)
**Clase:** `CurrencyTransformer`

- Recibe el DF crudo y lo transforma a la estructura pedida:
  - Renombra campos
  - Convierte el `timestamp` a `datetime UTC` con formato legible
  - Reordena columnas
- Guarda el archivo como `.parquet` en `data/o2_silver/`

‚úîÔ∏è Usar `.parquet` permite eficiencia de almacenamiento y velocidad en lecturas posteriores.

---

### üîπ 4. Modelado / Exportaci√≥n (`o4_modeling`)
**Clase:** `CurrencyModeler`

- Copia el `.parquet` desde Silver a Gold
- Convierte el `.parquet` a `.csv` con separador `;` y codificaci√≥n `utf-8-sig` (compatible con Excel)
- Guarda ambos archivos en `data/o3_gold/`

‚úîÔ∏è Esto permite cumplir con la consigna del CSV, pero conservar la eficiencia del `.parquet`.

---

### üîπ 5. Serving / BigQuery (`o5_serving`)
**Clase:** `CargadorBigQuery`

- Recorre todos los `.parquet` dentro de `data/o3_gold/`
- Sube cada archivo a BigQuery usando `pandas_gbq` con autodetecci√≥n de esquema
- Se autentica v√≠a `.json` en `meli_key.json`

‚úîÔ∏è Esto permite usar Looker Studio, Data Studio u otras herramientas para consumo de datos.

---

## ‚ñ∂Ô∏è Ejecuci√≥n del pipeline completo

El archivo `main.py` orquesta todo el proceso:

```bash
python notebooks/main.py
```

---

---

## üîö Conclusi√≥n

Este proyecto fue mucho m√°s que una simple extracci√≥n y transformaci√≥n de datos: lo abord√© como un desaf√≠o real de ingenier√≠a de datos, priorizando la claridad, la modularidad y la posibilidad de escalar o modificar el proceso con facilidad.

Cada etapa del pipeline fue pensada para ser reutilizable y entendible por cualquier analista o desarrollador que se sume al proyecto. Separar la l√≥gica en capas (bronze, silver y gold), aplicar logs por m√≥dulo y mantener cada clase con una √∫nica responsabilidad me permiti√≥ construir una soluci√≥n ordenada y profesional.

Adem√°s, complement√© el entregable solicitado (archivo `.csv`) con formatos y flujos que se utilizan en la pr√°ctica (como `.parquet` y BigQuery), lo cual suma valor al proceso y lo prepara para integraciones futuras.

Estoy conforme con el resultado final: el proyecto qued√≥ robusto, claro, trazable y alineado a est√°ndares de trabajo en datos reales.
